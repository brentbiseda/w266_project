{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on Hugging Face Transformers\n",
    "\n",
    "https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import transformers as ppb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-cased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-cased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/ADR/train.tsv\", sep=\"\\t\", header=None)\n",
    "test_df = pd.read_csv(\"../datasets/ADR/test.tsv\", sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate long sentences to 128 tokens\n",
    "X = df[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=128)))\n",
    "y = np.array(df[1])\n",
    "del df\n",
    "\n",
    "X_test = test_df[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=128)))\n",
    "y_test = np.array(test_df[1])\n",
    "del test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot Encoding of y\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "\n",
    "y = encoder.transform(y)\n",
    "y = to_categorical(y)\n",
    "\n",
    "# One hot Encoding of y test\n",
    "y_oh = encoder.transform(y_test)\n",
    "y_oh = to_categorical(y_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetEmbeddings(tokenizedBatch):\n",
    "    max_len = 0\n",
    "    for i in tokenizedBatch.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenizedBatch.values])\n",
    "    \n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    \n",
    "    input_ids = torch.tensor(padded).to(torch.long)  \n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    features = last_hidden_states[0][:,0,:].numpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Embeddings for Batch: 1 of 6\n",
      "Generating Embeddings for Batch: 2 of 6\n",
      "Generating Embeddings for Batch: 3 of 6\n",
      "Generating Embeddings for Batch: 4 of 6\n",
      "Generating Embeddings for Batch: 5 of 6\n",
      "Generating Embeddings for Batch: 6 of 6\n",
      "Generating Test Embeddings for Batch: 1 of 2\n",
      "Generating Test Embeddings for Batch: 2 of 2\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1000\n",
    "all_embeddings = []\n",
    "all_embeddings_test = []\n",
    "\n",
    "# Process Training Set Embeddings\n",
    "batches = math.ceil(X.shape[0] / BATCH_SIZE)\n",
    "\n",
    "for i in range(1, batches+1):\n",
    "    print(\"Generating Embeddings for Batch:\",i,\"of\", batches)\n",
    "    batchEmbeddings = GetEmbeddings(X[(i-1)*BATCH_SIZE:i*BATCH_SIZE])\n",
    "    all_embeddings.append(batchEmbeddings)\n",
    "\n",
    "# Process Test Set Embeddings\n",
    "batches = math.ceil(X_test.shape[0] / BATCH_SIZE)\n",
    "\n",
    "for i in range(1, batches+1):\n",
    "    print(\"Generating Test Embeddings for Batch:\",i,\"of\", batches)\n",
    "    batchEmbeddings = GetEmbeddings(X_test[(i-1)*BATCH_SIZE:i*BATCH_SIZE])\n",
    "    all_embeddings_test.append(batchEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "all_embeddings_test = np.concatenate(all_embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../binary/bert_embeddings_twitter.npy', all_embeddings)\n",
    "np.save('../binary/y_twitter.npy', y)\n",
    "np.save('../binary/bert_embeddings_test_twitter.npy', all_embeddings_test)\n",
    "np.save('../binary/y_test_twitter.npy', y_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras \n",
    "from keras.layers import Input, Lambda, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "from keras.optimizers import adam, sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.load('../binary/bert_embeddings_twitter.npy')\n",
    "y = np.load('../binary/y_twitter.npy')\n",
    "all_embeddings_test = np.load('../binary/bert_embeddings_test_twitter.npy')\n",
    "y_oh = np.load('../binary/y_test_twitter.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd = sgd(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "optim = adam(lr=0.0003, beta_1=0.9, beta_2=0.999, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(): \n",
    "    embedding = Input(shape=(768,), dtype=\"float\")\n",
    "    dense1 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(embedding)\n",
    "    dense2 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense1)\n",
    "    dense3 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense2)\n",
    "    dense4 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense3)\n",
    "    dense5 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense4)\n",
    "    dense6 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense5)\n",
    "    dense7 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense6)\n",
    "    dense8 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense7)\n",
    "    dense9 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense8)\n",
    "    dense10 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense9)\n",
    "    pred = Dense(2, activation='sigmoid')(dense9)\n",
    "    model = Model(inputs=[embedding], outputs=pred)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'], )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bert = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1000)              769000    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 8,779,002\n",
      "Trainable params: 8,779,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bert.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss', patience=15)\n",
    "cb_list = [es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5911 samples, validate on 6 samples\n",
      "Epoch 1/1000\n",
      "5911/5911 [==============================] - 2s 286us/step - loss: 9.5584 - acc: 0.5023 - val_loss: 9.4203 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x00000215278B9620>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bisedab\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"C:\\Users\\bisedab\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n",
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x00000215278B9620>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bisedab\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"C:\\Users\\bisedab\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 9.4218 - acc: 0.6231 - val_loss: 9.2882 - val_acc: 0.6667\n",
      "Epoch 3/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 9.2846 - acc: 0.6275 - val_loss: 9.1429 - val_acc: 0.6667\n",
      "Epoch 4/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 9.1492 - acc: 0.5881 - val_loss: 9.0476 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 9.0208 - acc: 0.5018 - val_loss: 8.8776 - val_acc: 0.6667\n",
      "Epoch 6/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 8.8859 - acc: 0.6075 - val_loss: 8.7534 - val_acc: 0.6667\n",
      "Epoch 7/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 8.7511 - acc: 0.6759 - val_loss: 8.6568 - val_acc: 0.6667\n",
      "Epoch 8/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 8.6256 - acc: 0.6018 - val_loss: 8.4936 - val_acc: 0.6667\n",
      "Epoch 9/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 8.5224 - acc: 0.5781 - val_loss: 8.4010 - val_acc: 0.6667\n",
      "Epoch 10/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 8.3631 - acc: 0.6919 - val_loss: 8.2944 - val_acc: 0.5000\n",
      "Epoch 11/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 8.2438 - acc: 0.6913 - val_loss: 8.1744 - val_acc: 0.6667\n",
      "Epoch 12/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 8.1922 - acc: 0.6078 - val_loss: 8.0760 - val_acc: 0.5000\n",
      "Epoch 13/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 8.0009 - acc: 0.7068 - val_loss: 8.1040 - val_acc: 0.6667\n",
      "Epoch 14/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 8.0526 - acc: 0.5840 - val_loss: 7.8778 - val_acc: 0.6667\n",
      "Epoch 15/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 7.8497 - acc: 0.6552 - val_loss: 7.7841 - val_acc: 0.6667\n",
      "Epoch 16/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 7.8205 - acc: 0.5947 - val_loss: 7.6852 - val_acc: 0.6667\n",
      "Epoch 17/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 7.7052 - acc: 0.6087 - val_loss: 7.5975 - val_acc: 0.6667\n",
      "Epoch 18/1000\n",
      "5911/5911 [==============================] - 0s 10us/step - loss: 7.5792 - acc: 0.6603 - val_loss: 7.5310 - val_acc: 0.5000\n",
      "Epoch 19/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 7.4716 - acc: 0.7119 - val_loss: 7.4755 - val_acc: 0.5000\n",
      "Epoch 20/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 7.3963 - acc: 0.6977 - val_loss: 7.3956 - val_acc: 0.6667\n",
      "Epoch 21/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 7.3262 - acc: 0.6554 - val_loss: 7.3077 - val_acc: 0.6667\n",
      "Epoch 22/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 7.2365 - acc: 0.6608 - val_loss: 7.2156 - val_acc: 0.5000\n",
      "Epoch 23/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 7.1338 - acc: 0.6992 - val_loss: 7.1161 - val_acc: 0.5000\n",
      "Epoch 24/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 7.0362 - acc: 0.7173 - val_loss: 7.0067 - val_acc: 0.6667\n",
      "Epoch 25/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 6.9495 - acc: 0.7224 - val_loss: 6.9126 - val_acc: 0.6667\n",
      "Epoch 26/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 6.8660 - acc: 0.7016 - val_loss: 6.8248 - val_acc: 0.6667\n",
      "Epoch 27/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 6.7784 - acc: 0.6980 - val_loss: 6.7408 - val_acc: 0.6667\n",
      "Epoch 28/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 6.6846 - acc: 0.7068 - val_loss: 6.6638 - val_acc: 0.6667\n",
      "Epoch 29/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 6.5910 - acc: 0.7246 - val_loss: 6.5968 - val_acc: 0.5000\n",
      "Epoch 30/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 6.5155 - acc: 0.7322 - val_loss: 6.5065 - val_acc: 0.5000\n",
      "Epoch 31/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 6.4346 - acc: 0.7339 - val_loss: 6.4238 - val_acc: 0.6667\n",
      "Epoch 32/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 6.3485 - acc: 0.7307 - val_loss: 6.3565 - val_acc: 0.6667\n",
      "Epoch 33/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 6.2774 - acc: 0.7329 - val_loss: 6.2338 - val_acc: 0.6667\n",
      "Epoch 34/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 6.1844 - acc: 0.7425 - val_loss: 6.0984 - val_acc: 0.5000\n",
      "Epoch 35/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 6.1127 - acc: 0.7447 - val_loss: 6.0105 - val_acc: 0.6667\n",
      "Epoch 36/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 6.0288 - acc: 0.7542 - val_loss: 5.9541 - val_acc: 0.6667\n",
      "Epoch 37/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 5.9571 - acc: 0.7515 - val_loss: 5.8647 - val_acc: 0.6667\n",
      "Epoch 38/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 5.8864 - acc: 0.7586 - val_loss: 5.7453 - val_acc: 0.8333\n",
      "Epoch 39/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 5.8115 - acc: 0.7552 - val_loss: 5.6524 - val_acc: 0.8333\n",
      "Epoch 40/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 5.7447 - acc: 0.7567 - val_loss: 5.5790 - val_acc: 0.8333\n",
      "Epoch 41/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 5.6670 - acc: 0.7755 - val_loss: 5.5130 - val_acc: 0.8333\n",
      "Epoch 42/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 5.6015 - acc: 0.7733 - val_loss: 5.3915 - val_acc: 0.8333\n",
      "Epoch 43/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 5.5288 - acc: 0.7708 - val_loss: 5.3162 - val_acc: 0.8333\n",
      "Epoch 44/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 5.4583 - acc: 0.7765 - val_loss: 5.2930 - val_acc: 0.8333\n",
      "Epoch 45/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 5.4000 - acc: 0.7789 - val_loss: 5.1768 - val_acc: 0.8333\n",
      "Epoch 46/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 5.3341 - acc: 0.7726 - val_loss: 5.1566 - val_acc: 0.8333\n",
      "Epoch 47/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 5.2603 - acc: 0.7814 - val_loss: 5.0919 - val_acc: 0.8333\n",
      "Epoch 48/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 5.1925 - acc: 0.7879 - val_loss: 5.0255 - val_acc: 0.8333\n",
      "Epoch 49/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 5.1349 - acc: 0.7870 - val_loss: 5.0217 - val_acc: 0.8333\n",
      "Epoch 50/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 5.0779 - acc: 0.7995 - val_loss: 4.9234 - val_acc: 0.8333\n",
      "Epoch 51/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 5.0107 - acc: 0.7988 - val_loss: 4.8906 - val_acc: 0.8333\n",
      "Epoch 52/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 4.9441 - acc: 0.8109 - val_loss: 4.8298 - val_acc: 0.8333\n",
      "Epoch 53/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 4.8814 - acc: 0.8159 - val_loss: 4.7547 - val_acc: 0.8333\n",
      "Epoch 54/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 4.8243 - acc: 0.8097 - val_loss: 4.7993 - val_acc: 0.8333\n",
      "Epoch 55/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 4.7937 - acc: 0.8014 - val_loss: 4.6909 - val_acc: 0.8333\n",
      "Epoch 56/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 4.8621 - acc: 0.7050 - val_loss: 4.9152 - val_acc: 0.6667\n",
      "Epoch 57/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 4.8590 - acc: 0.6919 - val_loss: 4.7091 - val_acc: 0.6667\n",
      "Epoch 58/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 4.6762 - acc: 0.7538 - val_loss: 4.5774 - val_acc: 0.8333\n",
      "Epoch 59/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 4.6340 - acc: 0.7593 - val_loss: 4.5846 - val_acc: 0.8333\n",
      "Epoch 60/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 4.6268 - acc: 0.7066 - val_loss: 4.5141 - val_acc: 0.8333\n",
      "Epoch 61/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 4.5150 - acc: 0.8188 - val_loss: 4.5245 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 4.4946 - acc: 0.7811 - val_loss: 4.5020 - val_acc: 0.6667\n",
      "Epoch 63/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 4.4731 - acc: 0.7315 - val_loss: 4.4495 - val_acc: 0.6667\n",
      "Epoch 64/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 4.4088 - acc: 0.7596 - val_loss: 4.3564 - val_acc: 0.8333\n",
      "Epoch 65/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 4.3213 - acc: 0.8163 - val_loss: 4.2648 - val_acc: 0.6667\n",
      "Epoch 66/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 4.2856 - acc: 0.7907 - val_loss: 4.2054 - val_acc: 0.8333\n",
      "Epoch 67/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 4.2516 - acc: 0.7853 - val_loss: 4.1646 - val_acc: 0.8333\n",
      "Epoch 68/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 4.1617 - acc: 0.8215 - val_loss: 4.2219 - val_acc: 0.6667\n",
      "Epoch 69/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 4.1463 - acc: 0.7951 - val_loss: 4.1729 - val_acc: 0.6667\n",
      "Epoch 70/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 4.0989 - acc: 0.8026 - val_loss: 3.9768 - val_acc: 0.8333\n",
      "Epoch 71/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 4.0314 - acc: 0.8266 - val_loss: 3.8839 - val_acc: 0.8333\n",
      "Epoch 72/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 4.0231 - acc: 0.8071 - val_loss: 3.9209 - val_acc: 0.8333\n",
      "Epoch 73/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 3.9419 - acc: 0.8295 - val_loss: 3.9691 - val_acc: 0.6667\n",
      "Epoch 74/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 3.9273 - acc: 0.8124 - val_loss: 3.8242 - val_acc: 0.8333\n",
      "Epoch 75/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 3.8569 - acc: 0.8318 - val_loss: 3.6969 - val_acc: 1.0000\n",
      "Epoch 76/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 3.8379 - acc: 0.8230 - val_loss: 3.6796 - val_acc: 0.8333\n",
      "Epoch 77/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 3.7784 - acc: 0.8318 - val_loss: 3.7244 - val_acc: 0.8333\n",
      "Epoch 78/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 3.7493 - acc: 0.8325 - val_loss: 3.6674 - val_acc: 0.8333\n",
      "Epoch 79/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 3.7065 - acc: 0.8376 - val_loss: 3.5364 - val_acc: 1.0000\n",
      "Epoch 80/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 3.6626 - acc: 0.8393 - val_loss: 3.4867 - val_acc: 1.0000\n",
      "Epoch 81/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 3.6267 - acc: 0.8403 - val_loss: 3.5281 - val_acc: 0.8333\n",
      "Epoch 82/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 3.5841 - acc: 0.8486 - val_loss: 3.4887 - val_acc: 0.8333\n",
      "Epoch 83/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 3.5443 - acc: 0.8523 - val_loss: 3.3547 - val_acc: 1.0000\n",
      "Epoch 84/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 3.5111 - acc: 0.8415 - val_loss: 3.3615 - val_acc: 0.8333\n",
      "Epoch 85/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 3.4576 - acc: 0.8680 - val_loss: 3.3823 - val_acc: 0.8333\n",
      "Epoch 86/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 3.4286 - acc: 0.8584 - val_loss: 3.2316 - val_acc: 1.0000\n",
      "Epoch 87/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 3.3923 - acc: 0.8576 - val_loss: 3.2927 - val_acc: 0.8333\n",
      "Epoch 88/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 3.3501 - acc: 0.8652 - val_loss: 3.1720 - val_acc: 1.0000\n",
      "Epoch 89/1000\n",
      "5911/5911 [==============================] - 0s 10us/step - loss: 3.3038 - acc: 0.8758 - val_loss: 3.1185 - val_acc: 1.0000\n",
      "Epoch 90/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 3.2662 - acc: 0.8784 - val_loss: 3.1679 - val_acc: 0.8333\n",
      "Epoch 91/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 3.2420 - acc: 0.8723 - val_loss: 3.0694 - val_acc: 1.0000\n",
      "Epoch 92/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 3.2550 - acc: 0.8296 - val_loss: 3.6111 - val_acc: 0.6667\n",
      "Epoch 93/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 3.4986 - acc: 0.7141 - val_loss: 3.0837 - val_acc: 1.0000\n",
      "Epoch 94/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 3.1380 - acc: 0.8860 - val_loss: 3.5673 - val_acc: 0.6667\n",
      "Epoch 95/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 3.6113 - acc: 0.6129 - val_loss: 3.2951 - val_acc: 0.6667\n",
      "Epoch 96/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 3.1923 - acc: 0.8124 - val_loss: 3.3631 - val_acc: 0.6667\n",
      "Epoch 97/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 3.3549 - acc: 0.6495 - val_loss: 3.3239 - val_acc: 0.6667\n",
      "Epoch 98/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 3.3375 - acc: 0.6297 - val_loss: 3.2809 - val_acc: 0.6667\n",
      "Epoch 99/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 3.2717 - acc: 0.6764 - val_loss: 3.2543 - val_acc: 0.6667\n",
      "Epoch 100/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 3.2103 - acc: 0.7625 - val_loss: 3.2288 - val_acc: 0.6667\n",
      "Epoch 101/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 3.1621 - acc: 0.8442 - val_loss: 3.1986 - val_acc: 0.8333\n",
      "Epoch 102/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 3.1414 - acc: 0.8038 - val_loss: 3.2020 - val_acc: 0.8333\n",
      "Epoch 103/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 3.1420 - acc: 0.7187 - val_loss: 3.1979 - val_acc: 0.6667\n",
      "Epoch 104/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 3.1326 - acc: 0.6841 - val_loss: 3.1572 - val_acc: 0.6667\n",
      "Epoch 105/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 3.0952 - acc: 0.7122 - val_loss: 3.1005 - val_acc: 0.8333\n",
      "Epoch 106/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 3.0374 - acc: 0.7767 - val_loss: 3.0729 - val_acc: 0.6667\n",
      "Epoch 107/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.9863 - acc: 0.8313 - val_loss: 3.0573 - val_acc: 0.6667\n",
      "Epoch 108/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.9553 - acc: 0.8252 - val_loss: 3.0336 - val_acc: 0.6667\n",
      "Epoch 109/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 2.9336 - acc: 0.7950 - val_loss: 3.0114 - val_acc: 0.6667\n",
      "Epoch 110/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.9069 - acc: 0.7780 - val_loss: 2.9850 - val_acc: 0.6667\n",
      "Epoch 111/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.8674 - acc: 0.7931 - val_loss: 2.9356 - val_acc: 0.6667\n",
      "Epoch 112/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.8196 - acc: 0.8237 - val_loss: 2.8206 - val_acc: 0.6667\n",
      "Epoch 113/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.7962 - acc: 0.8339 - val_loss: 2.7119 - val_acc: 1.0000\n",
      "Epoch 114/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 2.7870 - acc: 0.8301 - val_loss: 2.7055 - val_acc: 0.8333\n",
      "Epoch 115/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.7364 - acc: 0.8444 - val_loss: 2.7749 - val_acc: 0.6667\n",
      "Epoch 116/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 2.7150 - acc: 0.8413 - val_loss: 2.7189 - val_acc: 0.6667\n",
      "Epoch 117/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.6868 - acc: 0.8444 - val_loss: 2.5457 - val_acc: 0.8333\n",
      "Epoch 118/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 2.6410 - acc: 0.8614 - val_loss: 2.4740 - val_acc: 1.0000\n",
      "Epoch 119/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.6309 - acc: 0.8464 - val_loss: 2.4620 - val_acc: 1.0000\n",
      "Epoch 120/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.5933 - acc: 0.8702 - val_loss: 2.4895 - val_acc: 0.8333\n",
      "Epoch 121/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.5734 - acc: 0.8686 - val_loss: 2.4676 - val_acc: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.5546 - acc: 0.8687 - val_loss: 2.3918 - val_acc: 1.0000\n",
      "Epoch 123/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.5203 - acc: 0.8828 - val_loss: 2.3631 - val_acc: 1.0000\n",
      "Epoch 124/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 2.5068 - acc: 0.8750 - val_loss: 2.3331 - val_acc: 1.0000\n",
      "Epoch 125/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.4695 - acc: 0.8900 - val_loss: 2.3299 - val_acc: 1.0000\n",
      "Epoch 126/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.4530 - acc: 0.8848 - val_loss: 2.2797 - val_acc: 1.0000\n",
      "Epoch 127/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.4185 - acc: 0.8951 - val_loss: 2.2510 - val_acc: 1.0000\n",
      "Epoch 128/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.4058 - acc: 0.8883 - val_loss: 2.2414 - val_acc: 1.0000\n",
      "Epoch 129/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.3720 - acc: 0.8985 - val_loss: 2.2189 - val_acc: 1.0000\n",
      "Epoch 130/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.3457 - acc: 0.9053 - val_loss: 2.1726 - val_acc: 1.0000\n",
      "Epoch 131/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.3394 - acc: 0.8965 - val_loss: 2.2881 - val_acc: 0.8333\n",
      "Epoch 132/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.3368 - acc: 0.8938 - val_loss: 2.1297 - val_acc: 1.0000\n",
      "Epoch 133/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.2746 - acc: 0.9198 - val_loss: 2.1212 - val_acc: 1.0000\n",
      "Epoch 134/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.2691 - acc: 0.9076 - val_loss: 2.2605 - val_acc: 1.0000\n",
      "Epoch 135/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 2.3141 - acc: 0.8751 - val_loss: 2.0849 - val_acc: 1.0000\n",
      "Epoch 136/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.2104 - acc: 0.9308 - val_loss: 2.1677 - val_acc: 1.0000\n",
      "Epoch 137/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.3096 - acc: 0.8584 - val_loss: 2.6559 - val_acc: 0.6667\n",
      "Epoch 138/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.5090 - acc: 0.7586 - val_loss: 2.5544 - val_acc: 0.6667\n",
      "Epoch 139/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.4045 - acc: 0.7779 - val_loss: 2.1311 - val_acc: 1.0000\n",
      "Epoch 140/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.1798 - acc: 0.9318 - val_loss: 2.5983 - val_acc: 0.6667\n",
      "Epoch 141/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.5972 - acc: 0.6716 - val_loss: 2.3781 - val_acc: 0.6667\n",
      "Epoch 142/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.2388 - acc: 0.8714 - val_loss: 2.4650 - val_acc: 0.6667\n",
      "Epoch 143/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.3958 - acc: 0.7112 - val_loss: 2.4690 - val_acc: 0.6667\n",
      "Epoch 144/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 2.4541 - acc: 0.6430 - val_loss: 2.4529 - val_acc: 0.6667\n",
      "Epoch 145/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.4422 - acc: 0.6403 - val_loss: 2.4339 - val_acc: 0.6667\n",
      "Epoch 146/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 2.4005 - acc: 0.6721 - val_loss: 2.4187 - val_acc: 0.6667\n",
      "Epoch 147/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.3472 - acc: 0.7349 - val_loss: 2.4040 - val_acc: 0.6667\n",
      "Epoch 148/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 2.2881 - acc: 0.8141 - val_loss: 2.3582 - val_acc: 0.8333\n",
      "Epoch 149/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.2400 - acc: 0.8731 - val_loss: 2.3233 - val_acc: 0.8333\n",
      "Epoch 150/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.2459 - acc: 0.8290 - val_loss: 2.3527 - val_acc: 0.8333\n",
      "Epoch 151/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.2887 - acc: 0.7611 - val_loss: 2.3068 - val_acc: 0.8333\n",
      "Epoch 152/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.2493 - acc: 0.7848 - val_loss: 2.2208 - val_acc: 0.8333\n",
      "Epoch 153/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.1784 - acc: 0.8657 - val_loss: 2.2560 - val_acc: 0.8333\n",
      "Epoch 154/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 2.1514 - acc: 0.8680 - val_loss: 2.2629 - val_acc: 0.6667\n",
      "Epoch 155/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 2.1455 - acc: 0.8371 - val_loss: 2.2502 - val_acc: 0.6667\n",
      "Epoch 156/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.1374 - acc: 0.8142 - val_loss: 2.2295 - val_acc: 0.6667\n",
      "Epoch 157/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.1130 - acc: 0.8166 - val_loss: 2.1751 - val_acc: 0.6667\n",
      "Epoch 158/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.0653 - acc: 0.8472 - val_loss: 2.0032 - val_acc: 1.0000\n",
      "Epoch 159/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.0131 - acc: 0.8867 - val_loss: 1.8986 - val_acc: 1.0000\n",
      "Epoch 160/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 2.0175 - acc: 0.8706 - val_loss: 1.8569 - val_acc: 1.0000\n",
      "Epoch 161/1000\n",
      "5911/5911 [==============================] - 0s 14us/step - loss: 2.0052 - acc: 0.8691 - val_loss: 1.8223 - val_acc: 1.0000\n",
      "Epoch 162/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 1.9523 - acc: 0.9007 - val_loss: 1.9009 - val_acc: 0.8333\n",
      "Epoch 163/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.9738 - acc: 0.8843 - val_loss: 1.7706 - val_acc: 1.0000\n",
      "Epoch 164/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 1.9230 - acc: 0.9092 - val_loss: 1.7477 - val_acc: 1.0000\n",
      "Epoch 165/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.9061 - acc: 0.9032 - val_loss: 1.7381 - val_acc: 1.0000\n",
      "Epoch 166/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 1.8824 - acc: 0.9176 - val_loss: 1.7147 - val_acc: 1.0000\n",
      "Epoch 167/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.8639 - acc: 0.9207 - val_loss: 1.7095 - val_acc: 1.0000\n",
      "Epoch 168/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.8595 - acc: 0.9136 - val_loss: 1.7073 - val_acc: 1.0000\n",
      "Epoch 169/1000\n",
      "5911/5911 [==============================] - 0s 10us/step - loss: 1.8185 - acc: 0.9391 - val_loss: 1.7373 - val_acc: 1.0000\n",
      "Epoch 170/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 1.8401 - acc: 0.9169 - val_loss: 1.6835 - val_acc: 1.0000\n",
      "Epoch 171/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.8127 - acc: 0.9222 - val_loss: 1.6843 - val_acc: 1.0000\n",
      "Epoch 172/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 1.8135 - acc: 0.9147 - val_loss: 1.6851 - val_acc: 1.0000\n",
      "Epoch 173/1000\n",
      "5911/5911 [==============================] - 0s 12us/step - loss: 1.7643 - acc: 0.9514 - val_loss: 1.7107 - val_acc: 1.0000\n",
      "Epoch 174/1000\n",
      "5911/5911 [==============================] - 0s 10us/step - loss: 1.7902 - acc: 0.9201 - val_loss: 1.6878 - val_acc: 1.0000\n",
      "Epoch 175/1000\n",
      "5911/5911 [==============================] - 0s 10us/step - loss: 1.8070 - acc: 0.9019 - val_loss: 1.6519 - val_acc: 1.0000\n",
      "Epoch 176/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.7835 - acc: 0.9108 - val_loss: 1.6579 - val_acc: 1.0000\n",
      "Epoch 177/1000\n",
      "5911/5911 [==============================] - 0s 10us/step - loss: 1.7249 - acc: 0.9553 - val_loss: 1.6704 - val_acc: 1.0000\n",
      "Epoch 178/1000\n",
      "5911/5911 [==============================] - 0s 10us/step - loss: 1.7357 - acc: 0.9393 - val_loss: 1.5992 - val_acc: 1.0000\n",
      "Epoch 179/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.7504 - acc: 0.9136 - val_loss: 1.6079 - val_acc: 1.0000\n",
      "Epoch 180/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.7638 - acc: 0.9020 - val_loss: 1.5975 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.6681 - acc: 0.9599 - val_loss: 1.8747 - val_acc: 0.8333\n",
      "Epoch 182/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.8687 - acc: 0.8259 - val_loss: 2.1700 - val_acc: 0.6667\n",
      "Epoch 183/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.0117 - acc: 0.7843 - val_loss: 2.3557 - val_acc: 0.6667\n",
      "Epoch 184/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 2.2274 - acc: 0.6885 - val_loss: 2.0517 - val_acc: 0.6667\n",
      "Epoch 185/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.8970 - acc: 0.7850 - val_loss: 1.7451 - val_acc: 1.0000\n",
      "Epoch 186/1000\n",
      "5911/5911 [==============================] - 0s 13us/step - loss: 1.7243 - acc: 0.9311 - val_loss: 1.9361 - val_acc: 0.6667\n",
      "Epoch 187/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.9126 - acc: 0.7828 - val_loss: 1.8429 - val_acc: 0.8333\n",
      "Epoch 188/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.8299 - acc: 0.8488 - val_loss: 1.8486 - val_acc: 1.0000\n",
      "Epoch 189/1000\n",
      "5911/5911 [==============================] - 0s 10us/step - loss: 1.7804 - acc: 0.9381 - val_loss: 1.9690 - val_acc: 0.8333\n",
      "Epoch 190/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.8219 - acc: 0.8875 - val_loss: 2.0015 - val_acc: 0.6667\n",
      "Epoch 191/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.8518 - acc: 0.8413 - val_loss: 1.9978 - val_acc: 0.6667\n",
      "Epoch 192/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.8562 - acc: 0.8286 - val_loss: 1.9870 - val_acc: 0.6667\n",
      "Epoch 193/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.8358 - acc: 0.8408 - val_loss: 1.9476 - val_acc: 0.8333\n",
      "Epoch 194/1000\n",
      "5911/5911 [==============================] - 0s 10us/step - loss: 1.7953 - acc: 0.8790 - val_loss: 1.8056 - val_acc: 1.0000\n",
      "Epoch 195/1000\n",
      "5911/5911 [==============================] - 0s 11us/step - loss: 1.7460 - acc: 0.9242 - val_loss: 1.7387 - val_acc: 1.0000\n",
      "Epoch 196/1000\n",
      "5911/5911 [==============================] - 0s 10us/step - loss: 1.7276 - acc: 0.9245 - val_loss: 1.7500 - val_acc: 0.8333\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model_bert.fit(all_embeddings, y, epochs=1000, batch_size=10000, \n",
    "                             validation_split = 0.001, callbacks=cb_list)\n",
    "    model_bert.save_weights('../model/bert_logistic_twitter/model_bert_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'g', label='Training Acc')\n",
    "plt.title('Training and validation Acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 10000\n",
    "batches = math.ceil(all_embeddings_test.shape[0] / bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Batch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x00000215278B9620>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bisedab\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"C:\\Users\\bisedab\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_probs = []\n",
    "    \n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    model_bert.load_weights('../model/bert_logistic_twitter/model_bert_weights.h5')\n",
    "\n",
    "    for i in range(1,batches+1):\n",
    "        print(\"Predicting Batch\",i)\n",
    "        new_text_pr = all_embeddings_test[(i-1)*bs:i*bs]\n",
    "        preds = model_bert.predict(new_text_pr)\n",
    "        all_probs.append(preds)\n",
    "        preds = encoder.inverse_transform(np.argmax(preds,axis=1))\n",
    "        all_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.concatenate(all_preds, axis=0)\n",
    "results_probs = np.concatenate(all_probs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"../output/ADR/bert_logistic_twitter/test_results.tsv\", results_probs, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"../output/ADR/bert_logistic_twitter/test_predictions.tsv\", results, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8695064232589588\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",sum(results==y_test)/results.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
