{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train_data = pd.read_csv(\"undersampled/train.tsv\", delimiter='\\t', lineterminator='\\n', header=None)\n",
    "dev_data = pd.read_csv(\"undersampled/dev.tsv\", delimiter='\\t', lineterminator='\\n', header=None)\n",
    "test_data = pd.read_csv(\"undersampled/test.tsv\", delimiter='\\t', lineterminator='\\n', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(835, 834, 834)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data.shape[0], dev_data.shape[0], test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1669"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_data = pd.concat([train_data, dev_data], axis=0)\n",
    "train_dev_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you take Byetta, Victoza, or Januvia, read ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Side Effects of Levaquin, Cipro May Increase R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finding out I'm allergic to fluoxetine was a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weird #Pristiq is sold by #Pfizer but also by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Somebody pass the cymbalta</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  If you take Byetta, Victoza, or Januvia, read ...  0\n",
       "1  Side Effects of Levaquin, Cipro May Increase R...  0\n",
       "2  Finding out I'm allergic to fluoxetine was a b...  1\n",
       "3  Weird #Pristiq is sold by #Pfizer but also by ...  0\n",
       "4                         Somebody pass the cymbalta  0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign x and y\n",
    "train_x = train_dev_data[0]\n",
    "test_x = test_data[0]\n",
    "train_y = train_dev_data[1]\n",
    "test_y = test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: 44.190000000000005% positive class\n",
      "test data: 11.03% positive class\n"
     ]
    }
   ],
   "source": [
    "print(f\"training data: {np.round(train_y.value_counts()[1]/train_data.shape[0],4)*100}% positive class\")\n",
    "print(f\"test data: {np.round(test_y.value_counts()[1]/test_data.shape[0],4)*100}% positive class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed:   13.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1),\n",
       "        preprocessor=<function preprocessor...one, vocabulary=None)), ('naivebayes', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)], 'vectorizer__max_df': [0.8, 0.9, 1.0], 'naivebayes__alpha': [0.01, 0.1, 1.0, 10.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessor(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'\\d+', 'DG', s)\n",
    "    s = re.sub(r'@\\w+', \"@USER\", s)\n",
    "    return s\n",
    "\n",
    "vect = CountVectorizer(preprocessor=preprocessor)\n",
    "nb = MultinomialNB(fit_prior=False)\n",
    "pipe = Pipeline(steps=[(\"vectorizer\", vect), (\"naivebayes\", nb)])\n",
    "param_grid = {\"vectorizer__ngram_range\": [(1,1),(1,2),(1,3)],\n",
    "              \"vectorizer__max_df\": [0.8,0.9,1.0],\n",
    "              \"naivebayes__alpha\": [0.01, 0.1, 1.0, 10.0]}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=3, verbose=1)\n",
    "search.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'naivebayes__alpha': 1.0,\n",
       " 'vectorizer__max_df': 0.8,\n",
       " 'vectorizer__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katie/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/katie/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/katie/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/katie/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/katie/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_naivebayes__alpha</th>\n",
       "      <th>param_vectorizer__max_df</th>\n",
       "      <th>param_vectorizer__ngram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.064144</td>\n",
       "      <td>0.817855</td>\n",
       "      <td>0.996405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.064373</td>\n",
       "      <td>0.817855</td>\n",
       "      <td>0.996405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.064236</td>\n",
       "      <td>0.817855</td>\n",
       "      <td>0.996405</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.106800</td>\n",
       "      <td>0.813062</td>\n",
       "      <td>0.998502</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.107644</td>\n",
       "      <td>0.813062</td>\n",
       "      <td>0.998502</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.106930</td>\n",
       "      <td>0.813062</td>\n",
       "      <td>0.998502</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.027561</td>\n",
       "      <td>0.810066</td>\n",
       "      <td>0.955961</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.026975</td>\n",
       "      <td>0.810066</td>\n",
       "      <td>0.955961</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.027318</td>\n",
       "      <td>0.810066</td>\n",
       "      <td>0.955961</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.104946</td>\n",
       "      <td>0.794488</td>\n",
       "      <td>0.998801</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.107367</td>\n",
       "      <td>0.794488</td>\n",
       "      <td>0.998801</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.110081</td>\n",
       "      <td>0.794488</td>\n",
       "      <td>0.998801</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.063357</td>\n",
       "      <td>0.792091</td>\n",
       "      <td>0.997603</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.065125</td>\n",
       "      <td>0.792091</td>\n",
       "      <td>0.997603</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.061615</td>\n",
       "      <td>0.792091</td>\n",
       "      <td>0.997603</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.114024</td>\n",
       "      <td>0.784901</td>\n",
       "      <td>0.999101</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.100129</td>\n",
       "      <td>0.784901</td>\n",
       "      <td>0.999101</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100328</td>\n",
       "      <td>0.784901</td>\n",
       "      <td>0.999101</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.059038</td>\n",
       "      <td>0.784302</td>\n",
       "      <td>0.999101</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.060573</td>\n",
       "      <td>0.784302</td>\n",
       "      <td>0.999101</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059003</td>\n",
       "      <td>0.784302</td>\n",
       "      <td>0.999101</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.782504</td>\n",
       "      <td>0.868483</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.116350</td>\n",
       "      <td>0.782504</td>\n",
       "      <td>0.868483</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.118818</td>\n",
       "      <td>0.782504</td>\n",
       "      <td>0.868483</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.064035</td>\n",
       "      <td>0.781905</td>\n",
       "      <td>0.815759</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.063448</td>\n",
       "      <td>0.781905</td>\n",
       "      <td>0.815759</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.084236</td>\n",
       "      <td>0.781905</td>\n",
       "      <td>0.815759</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.028255</td>\n",
       "      <td>0.780707</td>\n",
       "      <td>0.789096</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.031089</td>\n",
       "      <td>0.780707</td>\n",
       "      <td>0.789096</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.028065</td>\n",
       "      <td>0.780707</td>\n",
       "      <td>0.789096</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.025563</td>\n",
       "      <td>0.769922</td>\n",
       "      <td>0.962251</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.031020</td>\n",
       "      <td>0.769922</td>\n",
       "      <td>0.962251</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.028555</td>\n",
       "      <td>0.769922</td>\n",
       "      <td>0.962251</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.026333</td>\n",
       "      <td>0.765129</td>\n",
       "      <td>0.974833</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025481</td>\n",
       "      <td>0.765129</td>\n",
       "      <td>0.974833</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026548</td>\n",
       "      <td>0.765129</td>\n",
       "      <td>0.974833</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_test_score  mean_train_score param_naivebayes__alpha  \\\n",
       "22       0.064144         0.817855          0.996405                       1   \n",
       "19       0.064373         0.817855          0.996405                       1   \n",
       "25       0.064236         0.817855          0.996405                       1   \n",
       "26       0.106800         0.813062          0.998502                       1   \n",
       "20       0.107644         0.813062          0.998502                       1   \n",
       "23       0.106930         0.813062          0.998502                       1   \n",
       "21       0.027561         0.810066          0.955961                       1   \n",
       "24       0.026975         0.810066          0.955961                       1   \n",
       "18       0.027318         0.810066          0.955961                       1   \n",
       "14       0.104946         0.794488          0.998801                     0.1   \n",
       "17       0.107367         0.794488          0.998801                     0.1   \n",
       "11       0.110081         0.794488          0.998801                     0.1   \n",
       "10       0.063357         0.792091          0.997603                     0.1   \n",
       "13       0.065125         0.792091          0.997603                     0.1   \n",
       "16       0.061615         0.792091          0.997603                     0.1   \n",
       "8        0.114024         0.784901          0.999101                    0.01   \n",
       "5        0.100129         0.784901          0.999101                    0.01   \n",
       "2        0.100328         0.784901          0.999101                    0.01   \n",
       "7        0.059038         0.784302          0.999101                    0.01   \n",
       "1        0.060573         0.784302          0.999101                    0.01   \n",
       "4        0.059003         0.784302          0.999101                    0.01   \n",
       "29       0.117658         0.782504          0.868483                      10   \n",
       "32       0.116350         0.782504          0.868483                      10   \n",
       "35       0.118818         0.782504          0.868483                      10   \n",
       "28       0.064035         0.781905          0.815759                      10   \n",
       "31       0.063448         0.781905          0.815759                      10   \n",
       "34       0.084236         0.781905          0.815759                      10   \n",
       "27       0.028255         0.780707          0.789096                      10   \n",
       "30       0.031089         0.780707          0.789096                      10   \n",
       "33       0.028065         0.780707          0.789096                      10   \n",
       "15       0.025563         0.769922          0.962251                     0.1   \n",
       "12       0.031020         0.769922          0.962251                     0.1   \n",
       "9        0.028555         0.769922          0.962251                     0.1   \n",
       "6        0.026333         0.765129          0.974833                    0.01   \n",
       "3        0.025481         0.765129          0.974833                    0.01   \n",
       "0        0.026548         0.765129          0.974833                    0.01   \n",
       "\n",
       "   param_vectorizer__max_df param_vectorizer__ngram_range  \n",
       "22                      0.9                        (1, 2)  \n",
       "19                      0.8                        (1, 2)  \n",
       "25                        1                        (1, 2)  \n",
       "26                        1                        (1, 3)  \n",
       "20                      0.8                        (1, 3)  \n",
       "23                      0.9                        (1, 3)  \n",
       "21                      0.9                        (1, 1)  \n",
       "24                        1                        (1, 1)  \n",
       "18                      0.8                        (1, 1)  \n",
       "14                      0.9                        (1, 3)  \n",
       "17                        1                        (1, 3)  \n",
       "11                      0.8                        (1, 3)  \n",
       "10                      0.8                        (1, 2)  \n",
       "13                      0.9                        (1, 2)  \n",
       "16                        1                        (1, 2)  \n",
       "8                         1                        (1, 3)  \n",
       "5                       0.9                        (1, 3)  \n",
       "2                       0.8                        (1, 3)  \n",
       "7                         1                        (1, 2)  \n",
       "1                       0.8                        (1, 2)  \n",
       "4                       0.9                        (1, 2)  \n",
       "29                      0.8                        (1, 3)  \n",
       "32                      0.9                        (1, 3)  \n",
       "35                        1                        (1, 3)  \n",
       "28                      0.8                        (1, 2)  \n",
       "31                      0.9                        (1, 2)  \n",
       "34                        1                        (1, 2)  \n",
       "27                      0.8                        (1, 1)  \n",
       "30                      0.9                        (1, 1)  \n",
       "33                        1                        (1, 1)  \n",
       "15                        1                        (1, 1)  \n",
       "12                      0.9                        (1, 1)  \n",
       "9                       0.8                        (1, 1)  \n",
       "6                         1                        (1, 1)  \n",
       "3                       0.9                        (1, 1)  \n",
       "0                       0.8                        (1, 1)  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results = pd.DataFrame(search.cv_results_)[[\"mean_fit_time\",\"mean_test_score\",\"mean_train_score\",\n",
    "                                                   \"param_naivebayes__alpha\",\"param_vectorizer__max_df\", \n",
    "                                                   \"param_vectorizer__ngram_range\"]]\n",
    "search_results.sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.995\n",
      "f1-score: 0.988\n"
     ]
    }
   ],
   "source": [
    "train_pred = search.predict(train_x)\n",
    "print(f\"accuracy: {np.round(accuracy_score(train_pred, train_y),3)}\")\n",
    "print(f\"f1-score: {np.round(f1_score(train_pred, train_y),3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1292,    1],\n",
       "       [   8,  368]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(train_pred, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.888\n",
      "f1-score: 0.408\n"
     ]
    }
   ],
   "source": [
    "test_pred = search.predict(test_x)\n",
    "print(f\"accuracy: {np.round(accuracy_score(test_pred, test_y),3)}\")\n",
    "print(f\"f1-score: {np.round(f1_score(test_pred, test_y),3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[709,  60],\n",
       "       [ 33,  32]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_pred, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
