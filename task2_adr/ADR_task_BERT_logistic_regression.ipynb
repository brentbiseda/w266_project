{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on Hugging Face Transformers\n",
    "\n",
    "https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import transformers as ppb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-cased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-cased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/ADR/train.tsv\", sep=\"\\t\", header=None)\n",
    "test_df = pd.read_csv(\"../datasets/ADR/test.tsv\", sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate long sentences to 128 tokens\n",
    "X = df[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=128)))\n",
    "y = np.array(df[1])\n",
    "del df\n",
    "\n",
    "X_test = test_df[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=128)))\n",
    "y_test = np.array(test_df[1])\n",
    "del test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot Encoding of y\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "\n",
    "y = encoder.transform(y)\n",
    "y = to_categorical(y)\n",
    "\n",
    "# One hot Encoding of y test\n",
    "y_oh = encoder.transform(y_test)\n",
    "y_oh = to_categorical(y_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetEmbeddings(tokenizedBatch):\n",
    "    max_len = 0\n",
    "    for i in tokenizedBatch.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenizedBatch.values])\n",
    "    \n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    \n",
    "    input_ids = torch.tensor(padded).to(torch.long)  \n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    features = last_hidden_states[0][:,0,:].numpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Embeddings for Batch: 1 of 6\n",
      "Generating Embeddings for Batch: 2 of 6\n",
      "Generating Embeddings for Batch: 3 of 6\n",
      "Generating Embeddings for Batch: 4 of 6\n",
      "Generating Embeddings for Batch: 5 of 6\n",
      "Generating Embeddings for Batch: 6 of 6\n",
      "Generating Test Embeddings for Batch: 1 of 1\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1000\n",
    "all_embeddings = []\n",
    "all_embeddings_test = []\n",
    "\n",
    "# Process Training Set Embeddings\n",
    "batches = math.ceil(X.shape[0] / BATCH_SIZE)\n",
    "\n",
    "for i in range(1, batches+1):\n",
    "    print(\"Generating Embeddings for Batch:\",i,\"of\", batches)\n",
    "    batchEmbeddings = GetEmbeddings(X[(i-1)*BATCH_SIZE:i*BATCH_SIZE])\n",
    "    all_embeddings.append(batchEmbeddings)\n",
    "\n",
    "# Process Test Set Embeddings\n",
    "batches = math.ceil(X_test.shape[0] / BATCH_SIZE)\n",
    "\n",
    "for i in range(1, batches+1):\n",
    "    print(\"Generating Test Embeddings for Batch:\",i,\"of\", batches)\n",
    "    batchEmbeddings = GetEmbeddings(X_test[(i-1)*BATCH_SIZE:i*BATCH_SIZE])\n",
    "    all_embeddings_test.append(batchEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "all_embeddings_test = np.concatenate(all_embeddings_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../binary/bert_embeddings_twitter.npy', all_embeddings)\n",
    "np.save('../binary/y_twitter.npy', y)\n",
    "np.save('../binary/bert_embeddings_test_twitter.npy', all_embeddings_test)\n",
    "np.save('../binary/y_test_twitter.npy', y_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras \n",
    "from keras.layers import Input, Lambda, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "from keras.optimizers import adam, sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.load('../binary/bert_embeddings_twitter.npy')\n",
    "y = np.load('../binary/y_twitter.npy')\n",
    "all_embeddings_test = np.load('../binary/bert_embeddings_test_twitter.npy')\n",
    "y_oh = np.load('../binary/y_test_twitter.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd = sgd(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "optim = adam(lr=0.0003, beta_1=0.9, beta_2=0.999, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(): \n",
    "    embedding = Input(shape=(768,), dtype=\"float\")\n",
    "    dense1 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(embedding)\n",
    "    dense2 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense1)\n",
    "    dense3 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense2)\n",
    "    dense4 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense3)\n",
    "    dense5 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense4)\n",
    "    dense6 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense5)\n",
    "    dense7 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense6)\n",
    "    dense8 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense7)\n",
    "    dense9 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense8)\n",
    "    dense10 = Dense(1000, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(dense9)\n",
    "    pred = Dense(2, activation='sigmoid')(dense9)\n",
    "    model = Model(inputs=[embedding], outputs=pred)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'], )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bert = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1000)              769000    \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 8,779,002\n",
      "Trainable params: 8,779,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bert.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss', patience=15)\n",
    "cb_list = [es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x00000243C60A8620>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bisedab\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"C:\\Users\\bisedab\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n",
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x00000243C60A8620>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bisedab\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"C:\\Users\\bisedab\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5912 samples, validate on 6 samples\n",
      "Epoch 1/1000\n",
      "5912/5912 [==============================] - 3s 524us/step - loss: 9.5643 - acc: 0.5108 - val_loss: 9.4197 - val_acc: 0.8333\n",
      "Epoch 2/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 9.4266 - acc: 0.6536 - val_loss: 9.2862 - val_acc: 0.5000\n",
      "Epoch 3/1000\n",
      "5912/5912 [==============================] - 0s 15us/step - loss: 9.2895 - acc: 0.6228 - val_loss: 9.1194 - val_acc: 0.6667\n",
      "Epoch 4/1000\n",
      "5912/5912 [==============================] - 0s 15us/step - loss: 9.1613 - acc: 0.5010 - val_loss: 9.0427 - val_acc: 0.5000\n",
      "Epoch 5/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 9.0311 - acc: 0.5497 - val_loss: 8.8795 - val_acc: 0.6667\n",
      "Epoch 6/1000\n",
      "5912/5912 [==============================] - 0s 14us/step - loss: 8.8952 - acc: 0.6561 - val_loss: 8.6989 - val_acc: 0.6667\n",
      "Epoch 7/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 8.7741 - acc: 0.5450 - val_loss: 8.6353 - val_acc: 0.6667\n",
      "Epoch 8/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 8.6426 - acc: 0.6299 - val_loss: 8.4269 - val_acc: 0.8333\n",
      "Epoch 9/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 8.5000 - acc: 0.6984 - val_loss: 8.2454 - val_acc: 0.8333\n",
      "Epoch 10/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 8.3704 - acc: 0.6889 - val_loss: 8.4016 - val_acc: 0.5000\n",
      "Epoch 11/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 8.3551 - acc: 0.6054 - val_loss: 7.9423 - val_acc: 0.8333\n",
      "Epoch 12/1000\n",
      "5912/5912 [==============================] - 0s 10us/step - loss: 8.1677 - acc: 0.6801 - val_loss: 7.9428 - val_acc: 0.8333\n",
      "Epoch 13/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 8.0336 - acc: 0.7135 - val_loss: 7.8817 - val_acc: 0.6667\n",
      "Epoch 14/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 7.9445 - acc: 0.6999 - val_loss: 7.6938 - val_acc: 0.8333\n",
      "Epoch 15/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 7.8320 - acc: 0.7348 - val_loss: 7.5636 - val_acc: 0.8333\n",
      "Epoch 16/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 7.7391 - acc: 0.7182 - val_loss: 7.5624 - val_acc: 0.8333\n",
      "Epoch 17/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 7.6396 - acc: 0.7223 - val_loss: 7.4332 - val_acc: 0.8333\n",
      "Epoch 18/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 7.5316 - acc: 0.7375 - val_loss: 7.2340 - val_acc: 0.8333\n",
      "Epoch 19/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 7.4598 - acc: 0.7246 - val_loss: 7.3053 - val_acc: 0.8333\n",
      "Epoch 20/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 7.3631 - acc: 0.7204 - val_loss: 7.1485 - val_acc: 0.8333\n",
      "Epoch 21/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 7.2436 - acc: 0.7476 - val_loss: 6.9439 - val_acc: 0.8333\n",
      "Epoch 22/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 7.2024 - acc: 0.7307 - val_loss: 7.0263 - val_acc: 0.8333\n",
      "Epoch 23/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 7.0822 - acc: 0.7441 - val_loss: 6.9419 - val_acc: 0.8333\n",
      "Epoch 24/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 6.9950 - acc: 0.7480 - val_loss: 6.7180 - val_acc: 0.8333\n",
      "Epoch 25/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 6.9138 - acc: 0.7451 - val_loss: 6.6576 - val_acc: 0.8333\n",
      "Epoch 26/1000\n",
      "5912/5912 [==============================] - 0s 10us/step - loss: 6.8143 - acc: 0.7630 - val_loss: 6.7034 - val_acc: 0.8333\n",
      "Epoch 27/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 6.7455 - acc: 0.7593 - val_loss: 6.5714 - val_acc: 0.8333\n",
      "Epoch 28/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 6.6439 - acc: 0.7755 - val_loss: 6.3770 - val_acc: 0.8333\n",
      "Epoch 29/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 6.5842 - acc: 0.7534 - val_loss: 6.3740 - val_acc: 0.8333\n",
      "Epoch 30/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 6.4753 - acc: 0.7855 - val_loss: 6.3905 - val_acc: 0.8333\n",
      "Epoch 31/1000\n",
      "5912/5912 [==============================] - 0s 10us/step - loss: 6.4211 - acc: 0.7798 - val_loss: 6.1755 - val_acc: 0.8333\n",
      "Epoch 32/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 6.3264 - acc: 0.7781 - val_loss: 6.1137 - val_acc: 0.8333\n",
      "Epoch 33/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 6.2457 - acc: 0.7862 - val_loss: 6.1688 - val_acc: 0.8333\n",
      "Epoch 34/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 6.1881 - acc: 0.7906 - val_loss: 5.9823 - val_acc: 0.8333\n",
      "Epoch 35/1000\n",
      "5912/5912 [==============================] - 0s 14us/step - loss: 6.0919 - acc: 0.7967 - val_loss: 5.9037 - val_acc: 0.8333\n",
      "Epoch 36/1000\n",
      "5912/5912 [==============================] - 0s 14us/step - loss: 6.0213 - acc: 0.7979 - val_loss: 5.9576 - val_acc: 0.8333\n",
      "Epoch 37/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 5.9639 - acc: 0.7935 - val_loss: 5.7808 - val_acc: 0.8333\n",
      "Epoch 38/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 5.8731 - acc: 0.8078 - val_loss: 5.7258 - val_acc: 0.8333\n",
      "Epoch 39/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 5.7988 - acc: 0.8177 - val_loss: 5.7552 - val_acc: 0.8333\n",
      "Epoch 40/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 5.7459 - acc: 0.8053 - val_loss: 5.5608 - val_acc: 0.8333\n",
      "Epoch 41/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 5.6815 - acc: 0.8126 - val_loss: 5.6442 - val_acc: 0.8333\n",
      "Epoch 42/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 5.6181 - acc: 0.8043 - val_loss: 5.4669 - val_acc: 0.8333\n",
      "Epoch 43/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 5.5279 - acc: 0.8331 - val_loss: 5.4528 - val_acc: 0.8333\n",
      "Epoch 44/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 5.4511 - acc: 0.8341 - val_loss: 5.4186 - val_acc: 0.8333\n",
      "Epoch 45/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 5.3889 - acc: 0.8332 - val_loss: 5.2794 - val_acc: 0.8333\n",
      "Epoch 46/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 5.3447 - acc: 0.8290 - val_loss: 5.4031 - val_acc: 0.8333\n",
      "Epoch 47/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 5.3775 - acc: 0.7630 - val_loss: 5.1230 - val_acc: 0.8333\n",
      "Epoch 48/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 5.2882 - acc: 0.7585 - val_loss: 5.2122 - val_acc: 0.8333\n",
      "Epoch 49/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 5.1826 - acc: 0.8100 - val_loss: 5.1283 - val_acc: 0.8333\n",
      "Epoch 50/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 5.1067 - acc: 0.8315 - val_loss: 4.9731 - val_acc: 0.8333\n",
      "Epoch 51/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 5.0859 - acc: 0.8148 - val_loss: 4.9830 - val_acc: 0.8333\n",
      "Epoch 52/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 4.9791 - acc: 0.8515 - val_loss: 4.9685 - val_acc: 0.8333\n",
      "Epoch 53/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 4.9531 - acc: 0.8236 - val_loss: 4.8713 - val_acc: 0.8333\n",
      "Epoch 54/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 4.8606 - acc: 0.8564 - val_loss: 4.7839 - val_acc: 0.8333\n",
      "Epoch 55/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 4.8349 - acc: 0.8464 - val_loss: 4.8541 - val_acc: 0.8333\n",
      "Epoch 56/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 4.8105 - acc: 0.8163 - val_loss: 4.7554 - val_acc: 0.8333\n",
      "Epoch 57/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 4.6875 - acc: 0.8643 - val_loss: 4.5970 - val_acc: 0.8333\n",
      "Epoch 58/1000\n",
      "5912/5912 [==============================] - 0s 15us/step - loss: 4.7323 - acc: 0.8053 - val_loss: 4.8076 - val_acc: 0.8333\n",
      "Epoch 59/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 4.8466 - acc: 0.7226 - val_loss: 4.6365 - val_acc: 0.8333\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5912/5912 [==============================] - 0s 12us/step - loss: 4.5993 - acc: 0.8288 - val_loss: 4.4100 - val_acc: 0.8333\n",
      "Epoch 61/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 4.7436 - acc: 0.6842 - val_loss: 4.4714 - val_acc: 0.8333\n",
      "Epoch 62/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 4.4837 - acc: 0.8718 - val_loss: 4.4984 - val_acc: 0.8333\n",
      "Epoch 63/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 4.5327 - acc: 0.7919 - val_loss: 4.4654 - val_acc: 0.8333\n",
      "Epoch 64/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 4.5064 - acc: 0.7818 - val_loss: 4.3713 - val_acc: 0.8333\n",
      "Epoch 65/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 4.3980 - acc: 0.8495 - val_loss: 4.2737 - val_acc: 0.8333\n",
      "Epoch 66/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 4.3564 - acc: 0.8456 - val_loss: 4.2046 - val_acc: 0.8333\n",
      "Epoch 67/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 4.3524 - acc: 0.7980 - val_loss: 4.2197 - val_acc: 0.8333\n",
      "Epoch 68/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 4.2327 - acc: 0.8647 - val_loss: 4.2299 - val_acc: 0.8333\n",
      "Epoch 69/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 4.2233 - acc: 0.8327 - val_loss: 4.2080 - val_acc: 0.8333\n",
      "Epoch 70/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 4.1815 - acc: 0.8322 - val_loss: 4.1343 - val_acc: 0.8333\n",
      "Epoch 71/1000\n",
      "5912/5912 [==============================] - 0s 14us/step - loss: 4.0857 - acc: 0.8713 - val_loss: 4.0230 - val_acc: 0.8333\n",
      "Epoch 72/1000\n",
      "5912/5912 [==============================] - 0s 14us/step - loss: 4.1146 - acc: 0.8363 - val_loss: 4.1128 - val_acc: 0.8333\n",
      "Epoch 73/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 4.0040 - acc: 0.8694 - val_loss: 4.1214 - val_acc: 0.8333\n",
      "Epoch 74/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 4.0099 - acc: 0.8486 - val_loss: 3.9938 - val_acc: 0.8333\n",
      "Epoch 75/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 3.9059 - acc: 0.8890 - val_loss: 3.8473 - val_acc: 0.8333\n",
      "Epoch 76/1000\n",
      "5912/5912 [==============================] - 0s 10us/step - loss: 3.9362 - acc: 0.8415 - val_loss: 3.9897 - val_acc: 0.8333\n",
      "Epoch 77/1000\n",
      "5912/5912 [==============================] - 0s 10us/step - loss: 3.8663 - acc: 0.8713 - val_loss: 3.9557 - val_acc: 0.8333\n",
      "Epoch 78/1000\n",
      "5912/5912 [==============================] - 0s 10us/step - loss: 3.8367 - acc: 0.8689 - val_loss: 3.7614 - val_acc: 0.8333\n",
      "Epoch 79/1000\n",
      "5912/5912 [==============================] - 0s 10us/step - loss: 3.7779 - acc: 0.8916 - val_loss: 3.7529 - val_acc: 0.8333\n",
      "Epoch 80/1000\n",
      "5912/5912 [==============================] - 0s 10us/step - loss: 3.7214 - acc: 0.8990 - val_loss: 3.8496 - val_acc: 0.8333\n",
      "Epoch 81/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 3.7100 - acc: 0.8840 - val_loss: 3.7951 - val_acc: 0.8333\n",
      "Epoch 82/1000\n",
      "5912/5912 [==============================] - 0s 10us/step - loss: 3.6383 - acc: 0.9044 - val_loss: 3.6307 - val_acc: 0.8333\n",
      "Epoch 83/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 3.6665 - acc: 0.8593 - val_loss: 3.8102 - val_acc: 0.8333\n",
      "Epoch 84/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 3.6373 - acc: 0.8703 - val_loss: 3.7511 - val_acc: 0.8333\n",
      "Epoch 85/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 3.5586 - acc: 0.8960 - val_loss: 3.4858 - val_acc: 0.8333\n",
      "Epoch 86/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 3.6149 - acc: 0.8396 - val_loss: 3.7087 - val_acc: 0.8333\n",
      "Epoch 87/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 3.5600 - acc: 0.8611 - val_loss: 3.6647 - val_acc: 0.8333\n",
      "Epoch 88/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 3.5447 - acc: 0.8496 - val_loss: 3.4681 - val_acc: 0.8333\n",
      "Epoch 89/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 3.4095 - acc: 0.9303 - val_loss: 3.3332 - val_acc: 0.8333\n",
      "Epoch 90/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 3.5247 - acc: 0.8148 - val_loss: 3.5186 - val_acc: 0.8333\n",
      "Epoch 91/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 3.4253 - acc: 0.8682 - val_loss: 3.5342 - val_acc: 0.8333\n",
      "Epoch 92/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 3.5231 - acc: 0.7894 - val_loss: 3.4397 - val_acc: 0.8333\n",
      "Epoch 93/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 3.3646 - acc: 0.8758 - val_loss: 3.2950 - val_acc: 0.8333\n",
      "Epoch 94/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 3.3157 - acc: 0.9104 - val_loss: 3.2235 - val_acc: 0.8333\n",
      "Epoch 95/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 3.3747 - acc: 0.8231 - val_loss: 3.3378 - val_acc: 0.8333\n",
      "Epoch 96/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 3.2616 - acc: 0.8977 - val_loss: 3.3658 - val_acc: 0.8333\n",
      "Epoch 97/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 3.3569 - acc: 0.8099 - val_loss: 3.3226 - val_acc: 0.8333\n",
      "Epoch 98/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 3.2838 - acc: 0.8396 - val_loss: 3.2232 - val_acc: 0.8333\n",
      "Epoch 99/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 3.1462 - acc: 0.9320 - val_loss: 3.0346 - val_acc: 1.0000\n",
      "Epoch 100/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 3.2994 - acc: 0.7947 - val_loss: 3.2045 - val_acc: 0.8333\n",
      "Epoch 101/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 3.1014 - acc: 0.9180 - val_loss: 3.2621 - val_acc: 0.8333\n",
      "Epoch 102/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 3.1932 - acc: 0.8383 - val_loss: 3.2377 - val_acc: 0.8333\n",
      "Epoch 103/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 3.1477 - acc: 0.8528 - val_loss: 3.1391 - val_acc: 0.8333\n",
      "Epoch 104/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 3.0163 - acc: 0.9296 - val_loss: 2.9792 - val_acc: 0.8333\n",
      "Epoch 105/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 3.0940 - acc: 0.8689 - val_loss: 3.0496 - val_acc: 0.8333\n",
      "Epoch 106/1000\n",
      "5912/5912 [==============================] - 0s 10us/step - loss: 2.9604 - acc: 0.9445 - val_loss: 3.1350 - val_acc: 0.8333\n",
      "Epoch 107/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 2.9612 - acc: 0.9137 - val_loss: 3.1525 - val_acc: 0.8333\n",
      "Epoch 108/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 2.9579 - acc: 0.9039 - val_loss: 3.0560 - val_acc: 0.8333\n",
      "Epoch 109/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 2.8725 - acc: 0.9396 - val_loss: 2.8376 - val_acc: 0.8333\n",
      "Epoch 110/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 2.8986 - acc: 0.9261 - val_loss: 2.9825 - val_acc: 0.8333\n",
      "Epoch 111/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 2.8094 - acc: 0.9538 - val_loss: 3.0884 - val_acc: 0.8333\n",
      "Epoch 112/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 2.8211 - acc: 0.9339 - val_loss: 2.9787 - val_acc: 0.8333\n",
      "Epoch 113/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 2.7617 - acc: 0.9567 - val_loss: 2.6841 - val_acc: 1.0000\n",
      "Epoch 114/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 2.7880 - acc: 0.9354 - val_loss: 3.0736 - val_acc: 0.8333\n",
      "Epoch 115/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 2.7753 - acc: 0.9296 - val_loss: 3.0429 - val_acc: 0.8333\n",
      "Epoch 116/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 2.7550 - acc: 0.9298 - val_loss: 2.6233 - val_acc: 1.0000\n",
      "Epoch 117/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 2.6790 - acc: 0.9630 - val_loss: 2.5812 - val_acc: 1.0000\n",
      "Epoch 118/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 2.6763 - acc: 0.9560 - val_loss: 2.9745 - val_acc: 0.8333\n",
      "Epoch 119/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 2.6914 - acc: 0.9330 - val_loss: 2.9726 - val_acc: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 2.6868 - acc: 0.9266 - val_loss: 2.6450 - val_acc: 0.8333\n",
      "Epoch 121/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 2.5854 - acc: 0.9767 - val_loss: 2.5075 - val_acc: 1.0000\n",
      "Epoch 122/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 2.8050 - acc: 0.8177 - val_loss: 3.1994 - val_acc: 0.8333\n",
      "Epoch 123/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 3.2320 - acc: 0.7026 - val_loss: 3.3781 - val_acc: 0.6667\n",
      "Epoch 124/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 3.3083 - acc: 0.6275 - val_loss: 2.8922 - val_acc: 0.6667\n",
      "Epoch 125/1000\n",
      "5912/5912 [==============================] - 0s 10us/step - loss: 2.8803 - acc: 0.7380 - val_loss: 2.6846 - val_acc: 0.8333\n",
      "Epoch 126/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 2.7396 - acc: 0.8757 - val_loss: 2.6176 - val_acc: 1.0000\n",
      "Epoch 127/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 2.8278 - acc: 0.8197 - val_loss: 2.6047 - val_acc: 1.0000\n",
      "Epoch 128/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 2.9117 - acc: 0.7373 - val_loss: 2.6283 - val_acc: 1.0000\n",
      "Epoch 129/1000\n",
      "5912/5912 [==============================] - 0s 14us/step - loss: 2.8521 - acc: 0.7623 - val_loss: 2.6712 - val_acc: 1.0000\n",
      "Epoch 130/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 2.8059 - acc: 0.8298 - val_loss: 2.7020 - val_acc: 0.8333\n",
      "Epoch 131/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 2.8018 - acc: 0.8747 - val_loss: 2.7122 - val_acc: 0.8333\n",
      "Epoch 132/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 2.8055 - acc: 0.8911 - val_loss: 2.7075 - val_acc: 0.8333\n",
      "Epoch 133/1000\n",
      "5912/5912 [==============================] - 0s 11us/step - loss: 2.8000 - acc: 0.8843 - val_loss: 2.6877 - val_acc: 0.8333\n",
      "Epoch 134/1000\n",
      "5912/5912 [==============================] - 0s 12us/step - loss: 2.7829 - acc: 0.8846 - val_loss: 2.6558 - val_acc: 0.8333\n",
      "Epoch 135/1000\n",
      "5912/5912 [==============================] - 0s 14us/step - loss: 2.7554 - acc: 0.8882 - val_loss: 2.6181 - val_acc: 0.8333\n",
      "Epoch 136/1000\n",
      "5912/5912 [==============================] - 0s 13us/step - loss: 2.7214 - acc: 0.8792 - val_loss: 2.5837 - val_acc: 0.8333\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model_bert.fit(all_embeddings, y, epochs=1000, batch_size=10000, \n",
    "                             validation_split = 0.001, callbacks=cb_list)\n",
    "    model_bert.save_weights('../model/bert_logistic_twitter/model_bert_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'g', label='Training Acc')\n",
    "plt.title('Training and validation Acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 10000\n",
    "batches = math.ceil(all_embeddings_test.shape[0] / bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Batch 1\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_probs = []\n",
    "    \n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    model_bert.load_weights('../model/bert_logistic_twitter/model_bert_weights.h5')\n",
    "\n",
    "    for i in range(1,batches+1):\n",
    "        print(\"Predicting Batch\",i)\n",
    "        new_text_pr = all_embeddings_test[(i-1)*bs:i*bs]\n",
    "        preds = model_bert.predict(new_text_pr)\n",
    "        all_probs.append(preds)\n",
    "        preds = encoder.inverse_transform(np.argmax(preds,axis=1))\n",
    "        all_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.concatenate(all_preds, axis=0)\n",
    "results_probs = np.concatenate(all_probs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"../output/ADR/bert_logistic_twitter/test_results.tsv\", results_probs, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"../output/ADR/bert_logistic_twitter/test_predictions.tsv\", results, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8273381294964028\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",sum(results==y_test)/results.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
